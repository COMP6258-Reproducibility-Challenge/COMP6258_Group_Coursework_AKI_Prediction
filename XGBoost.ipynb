{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "T6peRBM-giez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def code_ethnicity(ethinicity):\n",
        "\n",
        "    if (ethinicity == 'white'): return 0\n",
        "    elif (ethinicity == 'unknown'): return 1\n",
        "    elif (ethinicity == 'minorities'): return 2"
      ],
      "metadata": {
        "id": "RDU-08nU2GXB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf0\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost\n",
        "\n",
        "data = pd.read_csv('cleaned_data.csv')\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "print(data.head())\n",
        "\n",
        "data['ethnicity'] = data['ethnicity'].map(code_ethnicity)\n",
        "X = data.drop('aki_stage', axis=1).values\n",
        "y = data['aki_stage'].values - 1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(data.info())\n",
        "# Separate training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model_xgboost = xgboost.XGBClassifier(learning_rate=0.1,\n",
        "                                      max_depth=5,\n",
        "                                      n_estimators=5000,\n",
        "                                      subsample=0.5,\n",
        "                                      colsample_bytree=0.9,\n",
        "                                      eval_metric='auc',\n",
        "                                      verbosity=1)\n",
        "\n",
        "eval_set = [(X_test, y_test)]\n",
        "\n",
        "model_xgboost.fit(X_train,\n",
        "                  y_train,\n",
        "                  early_stopping_rounds=10,\n",
        "                  eval_set=eval_set,\n",
        "                  verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ynE-acHKeiPK",
        "outputId": "add72e49-8848-4784-f9cd-76c4a43f6b52"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1786, 44)\n",
            "Index(['weight', 'aki_stage', 'delay_rrt', 'gender', 'admission_age',\n",
            "       'ethnicity', 'hematocrit_min', 'hematocrit_max', 'hemoglobin_min',\n",
            "       'hemoglobin_max', 'platelets_min', 'platelets_max', 'wbc_min',\n",
            "       'wbc_max', 'aniongap_min', 'aniongap_max', 'bicarbonate_min',\n",
            "       'bicarbonate_max', 'bun_min', 'bun_max', 'calcium_min', 'calcium_max',\n",
            "       'chloride_min', 'chloride_max', 'creatinine_min', 'creatinine_max',\n",
            "       'glucose_min', 'glucose_max', 'sodium_min', 'sodium_max',\n",
            "       'potassium_min', 'potassium_max', 'inr_max', 'pt_max', 'ptt_max',\n",
            "       'heart_rate_mean', 'sbp_mean', 'dbp_mean', 'mbp_mean', 'resp_rate_mean',\n",
            "       'temperature_mean', 'spo2_mean', 'glucose_mean', 'gcs_min'],\n",
            "      dtype='object')\n",
            "   weight  aki_stage  delay_rrt  gender  admission_age ethnicity  \\\n",
            "0  104.50          1          1       1      66.262081   unknown   \n",
            "1  100.00          1          1       1      70.489938   unknown   \n",
            "2   98.95          3          0       1      37.700917   unknown   \n",
            "3  105.70          3          1       0      59.967156     white   \n",
            "4   69.00          1          0       1      79.060470     white   \n",
            "\n",
            "   hematocrit_min  hematocrit_max  hemoglobin_min  hemoglobin_max  ...  \\\n",
            "0            31.4            31.9            11.3            11.3  ...   \n",
            "1            34.0            34.2            11.3            11.4  ...   \n",
            "2            27.1            29.4             9.9            10.4  ...   \n",
            "3            25.0            30.9             8.1            10.1  ...   \n",
            "4            38.0            38.0            13.2            13.2  ...   \n",
            "\n",
            "   ptt_max  heart_rate_mean    sbp_mean  dbp_mean   mbp_mean  resp_rate_mean  \\\n",
            "0     47.5        89.625000  132.500000   68.5000  83.090909       21.673077   \n",
            "1     25.0        84.208333  107.500000   56.4600  74.019231       17.134615   \n",
            "2     36.0        80.956522  101.958333   52.4375  67.541667       20.000000   \n",
            "3     51.3        87.521739  108.000000   56.4000  70.700000       24.086957   \n",
            "4     35.6        90.318182  140.800000   71.8500  88.285714       21.000000   \n",
            "\n",
            "   temperature_mean  spo2_mean  glucose_mean  gcs_min  \n",
            "0         37.405000  96.909091    257.500000       10  \n",
            "1         36.978000  96.680000    123.666667        3  \n",
            "2         36.132143  95.250000    152.625000        6  \n",
            "3         36.776667  96.478261    102.714286       13  \n",
            "4         36.620000  95.782609    124.000000       15  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1786 entries, 0 to 1785\n",
            "Data columns (total 44 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   weight            1786 non-null   float64\n",
            " 1   aki_stage         1786 non-null   int64  \n",
            " 2   delay_rrt         1786 non-null   int64  \n",
            " 3   gender            1786 non-null   int64  \n",
            " 4   admission_age     1786 non-null   float64\n",
            " 5   ethnicity         1786 non-null   int64  \n",
            " 6   hematocrit_min    1786 non-null   float64\n",
            " 7   hematocrit_max    1786 non-null   float64\n",
            " 8   hemoglobin_min    1786 non-null   float64\n",
            " 9   hemoglobin_max    1786 non-null   float64\n",
            " 10  platelets_min     1786 non-null   float64\n",
            " 11  platelets_max     1786 non-null   float64\n",
            " 12  wbc_min           1786 non-null   float64\n",
            " 13  wbc_max           1786 non-null   float64\n",
            " 14  aniongap_min      1786 non-null   float64\n",
            " 15  aniongap_max      1786 non-null   float64\n",
            " 16  bicarbonate_min   1786 non-null   float64\n",
            " 17  bicarbonate_max   1786 non-null   float64\n",
            " 18  bun_min           1786 non-null   float64\n",
            " 19  bun_max           1786 non-null   float64\n",
            " 20  calcium_min       1786 non-null   float64\n",
            " 21  calcium_max       1786 non-null   float64\n",
            " 22  chloride_min      1786 non-null   float64\n",
            " 23  chloride_max      1786 non-null   float64\n",
            " 24  creatinine_min    1786 non-null   float64\n",
            " 25  creatinine_max    1786 non-null   float64\n",
            " 26  glucose_min       1786 non-null   float64\n",
            " 27  glucose_max       1786 non-null   float64\n",
            " 28  sodium_min        1786 non-null   float64\n",
            " 29  sodium_max        1786 non-null   float64\n",
            " 30  potassium_min     1786 non-null   float64\n",
            " 31  potassium_max     1786 non-null   float64\n",
            " 32  inr_max           1786 non-null   float64\n",
            " 33  pt_max            1786 non-null   float64\n",
            " 34  ptt_max           1786 non-null   float64\n",
            " 35  heart_rate_mean   1786 non-null   float64\n",
            " 36  sbp_mean          1786 non-null   float64\n",
            " 37  dbp_mean          1786 non-null   float64\n",
            " 38  mbp_mean          1786 non-null   float64\n",
            " 39  resp_rate_mean    1786 non-null   float64\n",
            " 40  temperature_mean  1786 non-null   float64\n",
            " 41  spo2_mean         1786 non-null   float64\n",
            " 42  glucose_mean      1786 non-null   float64\n",
            " 43  gcs_min           1786 non-null   int64  \n",
            "dtypes: float64(39), int64(5)\n",
            "memory usage: 614.1 KB\n",
            "None\n",
            "[0]\tvalidation_0-auc:0.56351\n",
            "[1]\tvalidation_0-auc:0.52339\n",
            "[2]\tvalidation_0-auc:0.56443\n",
            "[3]\tvalidation_0-auc:0.54802\n",
            "[4]\tvalidation_0-auc:0.52871\n",
            "[5]\tvalidation_0-auc:0.54929\n",
            "[6]\tvalidation_0-auc:0.54538\n",
            "[7]\tvalidation_0-auc:0.54349\n",
            "[8]\tvalidation_0-auc:0.55739\n",
            "[9]\tvalidation_0-auc:0.54950\n",
            "[10]\tvalidation_0-auc:0.55464\n",
            "[11]\tvalidation_0-auc:0.55183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12]\tvalidation_0-auc:0.55347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
              "              num_parallel_tree=None, objective='multi:softprob', ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=5000, n_jobs=None,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model_xgboost.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmoal8p_hr8f",
        "outputId": "a15552dc-26a1-4dfc-d558-f0bfb943acfc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 69.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=3):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def _calculate_gain(self, y, residuals, hessians):\n",
        "        gradient = np.sum(residuals)\n",
        "        hessian = np.sum(hessians)\n",
        "        return gradient ** 2 / (hessian + 1e-6)\n",
        "\n",
        "    def _split(self, X, y, residuals, hessians, feature_idx, threshold):\n",
        "        left_mask = X[:, feature_idx] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "        return (X[left_mask], y[left_mask], residuals[left_mask], hessians[left_mask]), (X[right_mask], y[right_mask], residuals[right_mask], hessians[right_mask])\n",
        "\n",
        "    def _find_best_split(self, X, y, residuals, hessians):\n",
        "        best_split = {}\n",
        "        best_gain = -np.inf\n",
        "        n_samples, n_features = X.shape\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = X[:, feature_idx]\n",
        "            thresholds = np.unique(feature_values)\n",
        "            for threshold in thresholds:\n",
        "                (X_left, y_left, residuals_left, hessians_left), (X_right, y_right, residuals_right, hessians_right) = self._split(X, y, residuals, hessians, feature_idx, threshold)\n",
        "                if len(X_left) == 0 or len(X_right) == 0:\n",
        "                    continue\n",
        "                gain = self._calculate_gain(y, residuals_left, hessians_left) + self._calculate_gain(y, residuals_right, hessians_right)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = {\n",
        "                        'feature_idx': feature_idx,\n",
        "                        'threshold': threshold,\n",
        "                        'left': (X_left, y_left, residuals_left, hessians_left),\n",
        "                        'right': (X_right, y_right, residuals_right, hessians_right)\n",
        "                    }\n",
        "        return best_split\n",
        "\n",
        "    def _build_tree(self, X, y, residuals, hessians, depth):\n",
        "        if depth == self.max_depth or len(X) < 2:\n",
        "            return {'leaf_value': np.sum(residuals) / (np.sum(hessians) + 1e-6)}\n",
        "        else:\n",
        "            best_split = self._find_best_split(X, y, residuals, hessians)\n",
        "            if not best_split:\n",
        "                return {'leaf_value': np.sum(residuals) / (np.sum(hessians) + 1e-6)}\n",
        "            left_subtree = self._build_tree(*best_split['left'], depth + 1)\n",
        "            right_subtree = self._build_tree(*best_split['right'], depth + 1)\n",
        "            return {\n",
        "                'feature_idx': best_split['feature_idx'],\n",
        "                'threshold': best_split['threshold'],\n",
        "                'left': left_subtree,\n",
        "                'right': right_subtree\n",
        "            }\n",
        "\n",
        "    def fit(self, X, y, residuals, hessians):\n",
        "        self.tree = self._build_tree(X, y, residuals, hessians, depth=0)\n",
        "\n",
        "    def _predict_single(self, x, node):\n",
        "        if 'leaf_value' in node:\n",
        "            return node['leaf_value']\n",
        "        if x[node['feature_idx']] <= node['threshold']:\n",
        "            return self._predict_single(x, node['left'])\n",
        "        else:\n",
        "            return self._predict_single(x, node['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
        "\n",
        "class XGBoost:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "\n",
        "    def _compute_gradients_and_hessians(self, y, y_pred):\n",
        "        residuals = y - y_pred\n",
        "        hessians = np.ones_like(y)\n",
        "        return residuals, hessians\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y_pred = np.zeros_like(y, dtype=float)\n",
        "        for _ in range(self.n_estimators):\n",
        "            residuals, hessians = self._compute_gradients_and_hessians(y, y_pred)\n",
        "            tree = DecisionTree(max_depth=self.max_depth)\n",
        "            tree.fit(X, y, residuals, hessians)\n",
        "            y_pred += self.learning_rate * tree.predict(X)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.zeros(X.shape[0], dtype=float)\n",
        "        for tree in self.trees:\n",
        "            y_pred += self.learning_rate * tree.predict(X)\n",
        "        return y_pred\n",
        "\n",
        "    def predict_classes(self, X):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.round(y_pred).astype(int)\n",
        "\n",
        "# Create and train XGBoost model\n",
        "xgb = XGBoost(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "print(\"run\")\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = xgb.predict_classes(X_test)\n",
        "\n",
        "# Evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBDyZar4giRo",
        "outputId": "4be52a1e-d05e-422a-d627-a6c8bf44a682"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "Accuracy: 58.10%\n"
          ]
        }
      ]
    }
  ]
}